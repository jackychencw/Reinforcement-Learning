{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bid9gvOfrEie"
   },
   "source": [
    "# **Exercise IV: Function Approximation**\n",
    "\n",
    "You will use function approximation to device controllers for the mountain car and/or cart pole problems in Assignment IV.\n",
    "\n",
    "Rather than code a function approximation class (straightforward but outside of the scope of our course), you'll use a library, TensorFlow, for this.\n",
    "\n",
    "There are two front ends for TensorFlow that make it easier to construct, debug, etc., neural networks (general nonlinear function approximation structures): Keras (keras.io) and TfLearn (tflearn.org).\n",
    "\n",
    "Consult the documentation for these two (either, your choice) and learn how to:\n",
    "\n",
    "Construct a neural network with several layers\n",
    "Obtain the gradient of the neural network with respect to its parameters\n",
    "Train the neural network by stochastic gradient descent using a loop that you construct and in which you update the weights as per the gradient and the error (you will use this in A-IV)\n",
    "Submit, via pdf, the results of your investigation. Graded for completion; this is an opportunity for you to ask questions in case you are stuck.\n",
    "\n",
    " \n",
    "\n",
    "Consult Files/stochastic_gradient_descent_example.py for one example to help you get started.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ba22fnc8_M79"
   },
   "outputs": [],
   "source": [
    "!pip install gym pyvirtualdisplay > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NzqdlgETohj7"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from IPython import display\n",
    "from pyvirtualdisplay import Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2SCGCWL70b9",
    "outputId": "4f404e7b-8d08-4c17-f421-a97aa03281b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step i 0 action= 1\n",
      "obs= [-5.08791404e-01 -1.11856857e-04] reward= -1.0 done= False info= {}\n",
      "step i 1 action= 1\n",
      "obs= [-5.09014280e-01 -2.22875621e-04] reward= -1.0 done= False info= {}\n",
      "step i 2 action= 2\n",
      "obs= [-0.5083465   0.00066778] reward= -1.0 done= False info= {}\n",
      "step i 3 action= 2\n",
      "obs= [-0.50679308  0.00155342] reward= -1.0 done= False info= {}\n",
      "step i 4 action= 2\n",
      "obs= [-0.50436565  0.00242743] reward= -1.0 done= False info= {}\n",
      "step i 5 action= 0\n",
      "obs= [-0.50308238  0.00128327] reward= -1.0 done= False info= {}\n",
      "step i 6 action= 0\n",
      "obs= [-5.02952891e-01  1.29489852e-04] reward= -1.0 done= False info= {}\n",
      "step i 7 action= 1\n",
      "obs= [-5.02978147e-01 -2.52552959e-05] reward= -1.0 done= False info= {}\n",
      "step i 8 action= 1\n",
      "obs= [-5.03157958e-01 -1.79811392e-04] reward= -1.0 done= False info= {}\n",
      "step i 9 action= 2\n",
      "obs= [-0.50249098  0.00066698] reward= -1.0 done= False info= {}\n",
      "step i 10 action= 2\n",
      "obs= [-0.5009822   0.00150878] reward= -1.0 done= False info= {}\n",
      "step i 11 action= 1\n",
      "obs= [-0.49964292  0.00133928] reward= -1.0 done= False info= {}\n",
      "step i 12 action= 0\n",
      "obs= [-4.99483154e-01  1.59767393e-04] reward= -1.0 done= False info= {}\n",
      "step i 13 action= 2\n",
      "obs= [-0.4985041   0.00097906] reward= -1.0 done= False info= {}\n",
      "step i 14 action= 2\n",
      "obs= [-0.49671307  0.00179103] reward= -1.0 done= False info= {}\n",
      "step i 15 action= 0\n",
      "obs= [-0.49612347  0.0005896 ] reward= -1.0 done= False info= {}\n",
      "step i 16 action= 1\n",
      "obs= [-4.95739700e-01  3.83769852e-04] reward= -1.0 done= False info= {}\n",
      "step i 17 action= 2\n",
      "obs= [-0.49456463  0.00117507] reward= -1.0 done= False info= {}\n",
      "step i 18 action= 0\n",
      "obs= [-4.94607041e-01 -4.24109054e-05] reward= -1.0 done= False info= {}\n",
      "step i 19 action= 2\n",
      "obs= [-0.49386662  0.00074043] reward= -1.0 done= False info= {}\n",
      "step i 20 action= 0\n",
      "obs= [-4.94348886e-01 -4.82270512e-04] reward= -1.0 done= False info= {}\n",
      "step i 21 action= 2\n",
      "obs= [-4.94050249e-01  2.98636738e-04] reward= -1.0 done= False info= {}\n",
      "step i 22 action= 2\n",
      "obs= [-0.49297294  0.00107731] reward= -1.0 done= False info= {}\n",
      "step i 23 action= 0\n",
      "obs= [-4.93124994e-01 -1.52057853e-04] reward= -1.0 done= False info= {}\n",
      "step i 24 action= 0\n",
      "obs= [-0.49450529 -0.00138029] reward= -1.0 done= False info= {}\n",
      "step i 25 action= 1\n",
      "obs= [-0.4961035  -0.00159822] reward= -1.0 done= False info= {}\n",
      "step i 26 action= 1\n",
      "obs= [-0.4979077 -0.0018042] reward= -1.0 done= False info= {}\n",
      "step i 27 action= 1\n",
      "obs= [-0.49990439 -0.00199669] reward= -1.0 done= False info= {}\n",
      "step i 28 action= 0\n",
      "obs= [-0.50307864 -0.00317425] reward= -1.0 done= False info= {}\n",
      "step i 29 action= 1\n",
      "obs= [-0.50640669 -0.00332805] reward= -1.0 done= False info= {}\n",
      "step i 30 action= 0\n",
      "obs= [-0.51086363 -0.00445694] reward= -1.0 done= False info= {}\n",
      "step i 31 action= 0\n",
      "obs= [-0.51641606 -0.00555243] reward= -1.0 done= False info= {}\n",
      "step i 32 action= 0\n",
      "obs= [-0.52302235 -0.00660629] reward= -1.0 done= False info= {}\n",
      "step i 33 action= 1\n",
      "obs= [-0.52963296 -0.00661062] reward= -1.0 done= False info= {}\n",
      "step i 34 action= 1\n",
      "obs= [-0.53619833 -0.00656536] reward= -1.0 done= False info= {}\n",
      "step i 35 action= 0\n",
      "obs= [-0.54366921 -0.00747089] reward= -1.0 done= False info= {}\n",
      "step i 36 action= 2\n",
      "obs= [-0.54998966 -0.00632045] reward= -1.0 done= False info= {}\n",
      "step i 37 action= 1\n",
      "obs= [-0.55611239 -0.00612273] reward= -1.0 done= False info= {}\n",
      "step i 38 action= 1\n",
      "obs= [-0.56199165 -0.00587926] reward= -1.0 done= False info= {}\n",
      "step i 39 action= 1\n",
      "obs= [-0.5675836  -0.00559195] reward= -1.0 done= False info= {}\n",
      "step i 40 action= 1\n",
      "obs= [-0.57284662 -0.00526302] reward= -1.0 done= False info= {}\n",
      "step i 41 action= 2\n",
      "obs= [-0.57674162 -0.003895  ] reward= -1.0 done= False info= {}\n",
      "step i 42 action= 1\n",
      "obs= [-0.58023974 -0.00349812] reward= -1.0 done= False info= {}\n",
      "step i 43 action= 0\n",
      "obs= [-0.58431509 -0.00407535] reward= -1.0 done= False info= {}\n",
      "step i 44 action= 0\n",
      "obs= [-0.58893758 -0.00462249] reward= -1.0 done= False info= {}\n",
      "step i 45 action= 2\n",
      "obs= [-0.59207317 -0.00313558] reward= -1.0 done= False info= {}\n",
      "step i 46 action= 1\n",
      "obs= [-0.5946988  -0.00262563] reward= -1.0 done= False info= {}\n",
      "step i 47 action= 2\n",
      "obs= [-0.59579522 -0.00109642] reward= -1.0 done= False info= {}\n",
      "step i 48 action= 2\n",
      "obs= [-5.95354382e-01  4.40834412e-04] reward= -1.0 done= False info= {}\n",
      "step i 49 action= 1\n",
      "obs= [-0.59437953  0.00097485] reward= -1.0 done= False info= {}\n",
      "step i 50 action= 2\n",
      "obs= [-0.5918778   0.00250173] reward= -1.0 done= False info= {}\n",
      "step i 51 action= 0\n",
      "obs= [-0.58986755  0.00201025] reward= -1.0 done= False info= {}\n",
      "step i 52 action= 0\n",
      "obs= [-0.58836355  0.001504  ] reward= -1.0 done= False info= {}\n",
      "step i 53 action= 2\n",
      "obs= [-0.58537687  0.00298668] reward= -1.0 done= False info= {}\n",
      "step i 54 action= 1\n",
      "obs= [-0.5819295   0.00344737] reward= -1.0 done= False info= {}\n",
      "step i 55 action= 1\n",
      "obs= [-0.57804688  0.00388262] reward= -1.0 done= False info= {}\n",
      "step i 56 action= 0\n",
      "obs= [-0.57475771  0.00328917] reward= -1.0 done= False info= {}\n",
      "step i 57 action= 0\n",
      "obs= [-0.57208635  0.00267136] reward= -1.0 done= False info= {}\n",
      "step i 58 action= 0\n",
      "obs= [-0.57005262  0.00203373] reward= -1.0 done= False info= {}\n",
      "step i 59 action= 0\n",
      "obs= [-0.56867161  0.00138101] reward= -1.0 done= False info= {}\n",
      "step i 60 action= 2\n",
      "obs= [-0.56595358  0.00271803] reward= -1.0 done= False info= {}\n",
      "step i 61 action= 1\n",
      "obs= [-0.56291875  0.00303483] reward= -1.0 done= False info= {}\n",
      "step i 62 action= 1\n",
      "obs= [-0.5595897   0.00332905] reward= -1.0 done= False info= {}\n",
      "step i 63 action= 0\n",
      "obs= [-0.55699124  0.00259846] reward= -1.0 done= False info= {}\n",
      "step i 64 action= 1\n",
      "obs= [-0.55414276  0.00284848] reward= -1.0 done= False info= {}\n",
      "step i 65 action= 2\n",
      "obs= [-0.55006552  0.00407724] reward= -1.0 done= False info= {}\n",
      "step i 66 action= 1\n",
      "obs= [-0.54578999  0.00427553] reward= -1.0 done= False info= {}\n",
      "step i 67 action= 1\n",
      "obs= [-0.54134814  0.00444184] reward= -1.0 done= False info= {}\n",
      "step i 68 action= 2\n",
      "obs= [-0.53577324  0.0055749 ] reward= -1.0 done= False info= {}\n",
      "step i 69 action= 1\n",
      "obs= [-0.53010705  0.00566619] reward= -1.0 done= False info= {}\n",
      "step i 70 action= 0\n",
      "obs= [-0.52539205  0.004715  ] reward= -1.0 done= False info= {}\n",
      "step i 71 action= 2\n",
      "obs= [-0.5196636   0.00572845] reward= -1.0 done= False info= {}\n",
      "step i 72 action= 2\n",
      "obs= [-0.51296467  0.00669894] reward= -1.0 done= False info= {}\n",
      "step i 73 action= 1\n",
      "obs= [-0.50634547  0.00661919] reward= -1.0 done= False info= {}\n",
      "step i 74 action= 1\n",
      "obs= [-0.49985562  0.00648985] reward= -1.0 done= False info= {}\n",
      "step i 75 action= 0\n",
      "obs= [-0.49454369  0.00531193] reward= -1.0 done= False info= {}\n",
      "step i 76 action= 0\n",
      "obs= [-0.4904494   0.00409429] reward= -1.0 done= False info= {}\n",
      "step i 77 action= 0\n",
      "obs= [-0.48760332  0.00284608] reward= -1.0 done= False info= {}\n",
      "step i 78 action= 2\n",
      "obs= [-0.48402668  0.00357664] reward= -1.0 done= False info= {}\n",
      "step i 79 action= 0\n",
      "obs= [-0.48174614  0.00228054] reward= -1.0 done= False info= {}\n",
      "step i 80 action= 2\n",
      "obs= [-0.47877866  0.00296747] reward= -1.0 done= False info= {}\n",
      "step i 81 action= 0\n",
      "obs= [-0.47714633  0.00163234] reward= -1.0 done= False info= {}\n",
      "step i 82 action= 1\n",
      "obs= [-0.47586126  0.00128507] reward= -1.0 done= False info= {}\n",
      "step i 83 action= 1\n",
      "obs= [-0.474933    0.00092826] reward= -1.0 done= False info= {}\n",
      "step i 84 action= 0\n",
      "obs= [-4.75368439e-01 -4.35438443e-04] reward= -1.0 done= False info= {}\n",
      "step i 85 action= 1\n",
      "obs= [-0.47616434 -0.00079591] reward= -1.0 done= False info= {}\n",
      "step i 86 action= 0\n",
      "obs= [-0.47831481 -0.00215046] reward= -1.0 done= False info= {}\n",
      "step i 87 action= 2\n",
      "obs= [-0.47980386 -0.00148905] reward= -1.0 done= False info= {}\n",
      "step i 88 action= 0\n",
      "obs= [-0.48262043 -0.00281657] reward= -1.0 done= False info= {}\n",
      "step i 89 action= 2\n",
      "obs= [-0.48474356 -0.00212313] reward= -1.0 done= False info= {}\n",
      "step i 90 action= 1\n",
      "obs= [-0.48715744 -0.00241389] reward= -1.0 done= False info= {}\n",
      "step i 91 action= 2\n",
      "obs= [-0.4888441  -0.00168665] reward= -1.0 done= False info= {}\n",
      "step i 92 action= 1\n",
      "obs= [-0.49079094 -0.00194684] reward= -1.0 done= False info= {}\n",
      "step i 93 action= 0\n",
      "obs= [-0.49398344 -0.0031925 ] reward= -1.0 done= False info= {}\n",
      "step i 94 action= 0\n",
      "obs= [-0.49839776 -0.00441432] reward= -1.0 done= False info= {}\n",
      "step i 95 action= 0\n",
      "obs= [-0.50400092 -0.00560315] reward= -1.0 done= False info= {}\n",
      "step i 96 action= 0\n",
      "obs= [-0.51075097 -0.00675005] reward= -1.0 done= False info= {}\n",
      "step i 97 action= 0\n",
      "obs= [-0.51859735 -0.00784639] reward= -1.0 done= False info= {}\n",
      "step i 98 action= 1\n",
      "obs= [-0.52648125 -0.0078839 ] reward= -1.0 done= False info= {}\n",
      "step i 99 action= 2\n",
      "obs= [-0.53334353 -0.00686228] reward= -1.0 done= False info= {}\n",
      "step i 100 action= 1\n",
      "obs= [-0.54013273 -0.0067892 ] reward= -1.0 done= False info= {}\n",
      "step i 101 action= 1\n",
      "obs= [-0.54679798 -0.00666525] reward= -1.0 done= False info= {}\n",
      "step i 102 action= 1\n",
      "obs= [-0.55328937 -0.00649139] reward= -1.0 done= False info= {}\n",
      "step i 103 action= 1\n",
      "obs= [-0.55955838 -0.00626901] reward= -1.0 done= False info= {}\n",
      "step i 104 action= 2\n",
      "obs= [-0.56455822 -0.00499984] reward= -1.0 done= False info= {}\n",
      "step i 105 action= 2\n",
      "obs= [-0.56825163 -0.00369341] reward= -1.0 done= False info= {}\n",
      "step i 106 action= 2\n",
      "obs= [-0.57061115 -0.00235952] reward= -1.0 done= False info= {}\n",
      "step i 107 action= 2\n",
      "obs= [-0.57161924 -0.00100809] reward= -1.0 done= False info= {}\n",
      "step i 108 action= 1\n",
      "obs= [-0.57226842 -0.00064918] reward= -1.0 done= False info= {}\n",
      "step i 109 action= 0\n",
      "obs= [-0.57355388 -0.00128546] reward= -1.0 done= False info= {}\n",
      "step i 110 action= 2\n",
      "obs= [-5.73466070e-01  8.78067322e-05] reward= -1.0 done= False info= {}\n",
      "step i 111 action= 0\n",
      "obs= [-5.74005652e-01 -5.39582085e-04] reward= -1.0 done= False info= {}\n",
      "step i 112 action= 2\n",
      "obs= [-0.57316862  0.00083703] reward= -1.0 done= False info= {}\n",
      "step i 113 action= 1\n",
      "obs= [-0.57196119  0.00120744] reward= -1.0 done= False info= {}\n",
      "step i 114 action= 1\n",
      "obs= [-0.5703923   0.00156888] reward= -1.0 done= False info= {}\n",
      "step i 115 action= 2\n",
      "obs= [-0.56747362  0.00291868] reward= -1.0 done= False info= {}\n",
      "step i 116 action= 1\n",
      "obs= [-0.56422683  0.00324679] reward= -1.0 done= False info= {}\n",
      "step i 117 action= 2\n",
      "obs= [-0.55967608  0.00455075] reward= -1.0 done= False info= {}\n",
      "step i 118 action= 1\n",
      "obs= [-0.55485527  0.0048208 ] reward= -1.0 done= False info= {}\n",
      "step i 119 action= 2\n",
      "obs= [-0.54880039  0.00605488] reward= -1.0 done= False info= {}\n",
      "step i 120 action= 0\n",
      "obs= [-0.54355668  0.00524371] reward= -1.0 done= False info= {}\n",
      "step i 121 action= 2\n",
      "obs= [-0.53716337  0.00639331] reward= -1.0 done= False info= {}\n",
      "step i 122 action= 0\n",
      "obs= [-0.53166835  0.00549502] reward= -1.0 done= False info= {}\n",
      "step i 123 action= 0\n",
      "obs= [-0.52711282  0.00455553] reward= -1.0 done= False info= {}\n",
      "step i 124 action= 2\n",
      "obs= [-0.52153093  0.00558189] reward= -1.0 done= False info= {}\n",
      "step i 125 action= 1\n",
      "obs= [-0.51596455  0.00556638] reward= -1.0 done= False info= {}\n",
      "step i 126 action= 2\n",
      "obs= [-0.50945543  0.00650913] reward= -1.0 done= False info= {}\n",
      "step i 127 action= 1\n",
      "obs= [-0.50305234  0.00640308] reward= -1.0 done= False info= {}\n",
      "step i 128 action= 0\n",
      "obs= [-0.49780326  0.00524908] reward= -1.0 done= False info= {}\n",
      "step i 129 action= 1\n",
      "obs= [-0.49274745  0.00505581] reward= -1.0 done= False info= {}\n",
      "step i 130 action= 1\n",
      "obs= [-0.4879227   0.00482475] reward= -1.0 done= False info= {}\n",
      "step i 131 action= 1\n",
      "obs= [-0.483365    0.00455769] reward= -1.0 done= False info= {}\n",
      "step i 132 action= 2\n",
      "obs= [-0.47810833  0.00525667] reward= -1.0 done= False info= {}\n",
      "step i 133 action= 1\n",
      "obs= [-0.47319178  0.00491655] reward= -1.0 done= False info= {}\n",
      "step i 134 action= 1\n",
      "obs= [-0.46865184  0.00453994] reward= -1.0 done= False info= {}\n",
      "step i 135 action= 2\n",
      "obs= [-0.46352214  0.0051297 ] reward= -1.0 done= False info= {}\n",
      "step i 136 action= 2\n",
      "obs= [-0.45784057  0.00568156] reward= -1.0 done= False info= {}\n",
      "step i 137 action= 1\n",
      "obs= [-0.45264901  0.00519157] reward= -1.0 done= False info= {}\n",
      "step i 138 action= 1\n",
      "obs= [-0.44798555  0.00466345] reward= -1.0 done= False info= {}\n",
      "step i 139 action= 2\n",
      "obs= [-0.44288435  0.00510121] reward= -1.0 done= False info= {}\n",
      "step i 140 action= 2\n",
      "obs= [-0.4373826   0.00550175] reward= -1.0 done= False info= {}\n",
      "step i 141 action= 2\n",
      "obs= [-0.43152029  0.00586231] reward= -1.0 done= False info= {}\n",
      "step i 142 action= 2\n",
      "obs= [-0.42533982  0.00618047] reward= -1.0 done= False info= {}\n",
      "step i 143 action= 0\n",
      "obs= [-0.42088566  0.00445415] reward= -1.0 done= False info= {}\n",
      "step i 144 action= 2\n",
      "obs= [-0.41618973  0.00469594] reward= -1.0 done= False info= {}\n",
      "step i 145 action= 1\n",
      "obs= [-0.41228549  0.00390424] reward= -1.0 done= False info= {}\n",
      "step i 146 action= 1\n",
      "obs= [-0.40920066  0.00308482] reward= -1.0 done= False info= {}\n",
      "step i 147 action= 0\n",
      "obs= [-0.40795709  0.00124358] reward= -1.0 done= False info= {}\n",
      "step i 148 action= 2\n",
      "obs= [-0.40656353  0.00139356] reward= -1.0 done= False info= {}\n",
      "step i 149 action= 1\n",
      "obs= [-0.40602981  0.00053372] reward= -1.0 done= False info= {}\n",
      "step i 150 action= 0\n",
      "obs= [-0.40735969 -0.00132988] reward= -1.0 done= False info= {}\n",
      "step i 151 action= 0\n",
      "obs= [-0.4105438  -0.00318411] reward= -1.0 done= False info= {}\n",
      "step i 152 action= 2\n",
      "obs= [-0.41355966 -0.00301586] reward= -1.0 done= False info= {}\n",
      "step i 153 action= 1\n",
      "obs= [-0.41738591 -0.00382625] reward= -1.0 done= False info= {}\n",
      "step i 154 action= 2\n",
      "obs= [-0.42099534 -0.00360943] reward= -1.0 done= False info= {}\n",
      "step i 155 action= 2\n",
      "obs= [-0.4243622  -0.00336686] reward= -1.0 done= False info= {}\n",
      "step i 156 action= 1\n",
      "obs= [-0.42846239 -0.00410019] reward= -1.0 done= False info= {}\n",
      "step i 157 action= 0\n",
      "obs= [-0.43426646 -0.00580407] reward= -1.0 done= False info= {}\n",
      "step i 158 action= 2\n",
      "obs= [-0.43973252 -0.00546607] reward= -1.0 done= False info= {}\n",
      "step i 159 action= 0\n",
      "obs= [-0.44682097 -0.00708845] reward= -1.0 done= False info= {}\n",
      "step i 160 action= 0\n",
      "obs= [-0.45548018 -0.0086592 ] reward= -1.0 done= False info= {}\n",
      "step i 161 action= 1\n",
      "obs= [-0.46464672 -0.00916655] reward= -1.0 done= False info= {}\n",
      "step i 162 action= 0\n",
      "obs= [-0.47525311 -0.01060638] reward= -1.0 done= False info= {}\n",
      "step i 163 action= 1\n",
      "obs= [-0.48622081 -0.01096771] reward= -1.0 done= False info= {}\n",
      "step i 164 action= 0\n",
      "obs= [-0.49846827 -0.01224745] reward= -1.0 done= False info= {}\n",
      "step i 165 action= 0\n",
      "obs= [-0.51190402 -0.01343575] reward= -1.0 done= False info= {}\n",
      "step i 166 action= 2\n",
      "obs= [-0.52442747 -0.01252345] reward= -1.0 done= False info= {}\n",
      "step i 167 action= 0\n",
      "obs= [-0.5379447  -0.01351723] reward= -1.0 done= False info= {}\n",
      "step i 168 action= 2\n",
      "obs= [-0.55035437 -0.01240967] reward= -1.0 done= False info= {}\n",
      "step i 169 action= 2\n",
      "obs= [-0.56156359 -0.01120922] reward= -1.0 done= False info= {}\n",
      "step i 170 action= 1\n",
      "obs= [-0.57248869 -0.0109251 ] reward= -1.0 done= False info= {}\n",
      "step i 171 action= 1\n",
      "obs= [-0.58304843 -0.01055974] reward= -1.0 done= False info= {}\n",
      "step i 172 action= 2\n",
      "obs= [-0.59216465 -0.00911622] reward= -1.0 done= False info= {}\n",
      "step i 173 action= 2\n",
      "obs= [-0.59977025 -0.0076056 ] reward= -1.0 done= False info= {}\n",
      "step i 174 action= 2\n",
      "obs= [-0.60580953 -0.00603927] reward= -1.0 done= False info= {}\n",
      "step i 175 action= 0\n",
      "obs= [-0.61223845 -0.00642892] reward= -1.0 done= False info= {}\n",
      "step i 176 action= 1\n",
      "obs= [-0.61801038 -0.00577193] reward= -1.0 done= False info= {}\n",
      "step i 177 action= 2\n",
      "obs= [-0.62208366 -0.00407328] reward= -1.0 done= False info= {}\n",
      "step i 178 action= 2\n",
      "obs= [-0.624429   -0.00234534] reward= -1.0 done= False info= {}\n",
      "step i 179 action= 0\n",
      "obs= [-0.62702959 -0.00260059] reward= -1.0 done= False info= {}\n",
      "step i 180 action= 0\n",
      "obs= [-0.62986684 -0.00283725] reward= -1.0 done= False info= {}\n",
      "step i 181 action= 0\n",
      "obs= [-0.63292051 -0.00305367] reward= -1.0 done= False info= {}\n",
      "step i 182 action= 2\n",
      "obs= [-0.63416889 -0.00124838] reward= -1.0 done= False info= {}\n",
      "step i 183 action= 1\n",
      "obs= [-6.34603115e-01 -4.34226212e-04] reward= -1.0 done= False info= {}\n",
      "step i 184 action= 2\n",
      "obs= [-0.63322011  0.001383  ] reward= -1.0 done= False info= {}\n",
      "step i 185 action= 0\n",
      "obs= [-0.63202969  0.00119042] reward= -1.0 done= False info= {}\n",
      "step i 186 action= 0\n",
      "obs= [-0.6310403   0.00098939] reward= -1.0 done= False info= {}\n",
      "step i 187 action= 2\n",
      "obs= [-0.62825898  0.00278132] reward= -1.0 done= False info= {}\n",
      "step i 188 action= 2\n",
      "obs= [-0.62370554  0.00455344] reward= -1.0 done= False info= {}\n",
      "step i 189 action= 2\n",
      "obs= [-0.61741254  0.006293  ] reward= -1.0 done= False info= {}\n",
      "step i 190 action= 0\n",
      "obs= [-0.61142518  0.00598735] reward= -1.0 done= False info= {}\n",
      "step i 191 action= 2\n",
      "obs= [-0.60378672  0.00763846] reward= -1.0 done= False info= {}\n",
      "step i 192 action= 0\n",
      "obs= [-0.59655264  0.00723408] reward= -1.0 done= False info= {}\n",
      "step i 193 action= 0\n",
      "obs= [-0.58977576  0.00677688] reward= -1.0 done= False info= {}\n",
      "step i 194 action= 1\n",
      "obs= [-0.58250581  0.00726995] reward= -1.0 done= False info= {}\n",
      "step i 195 action= 2\n",
      "obs= [-0.57379635  0.00870946] reward= -1.0 done= False info= {}\n",
      "step i 196 action= 0\n",
      "obs= [-0.56571183  0.00808452] reward= -1.0 done= False info= {}\n",
      "step i 197 action= 2\n",
      "obs= [-0.5563123   0.00939953] reward= -1.0 done= False info= {}\n",
      "step i 198 action= 2\n",
      "obs= [-0.54566781  0.01064449] reward= -1.0 done= False info= {}\n",
      "step i 199 action= 0\n",
      "obs= [-0.53585793  0.00980988] reward= -1.0 done= True info= {'TimeLimit.truncated': True}\n"
     ]
    }
   ],
   "source": [
    "class agent():\n",
    "  def __init__(self, env_name='MountainCar-v0'):\n",
    "    self.env = gym.make(env_name)\n",
    "\n",
    "  def choose_action(self, policy=None):\n",
    "    if not policy:\n",
    "      return self.env.action_space.sample()\n",
    "    else:\n",
    "      # TODO\n",
    "      return None\n",
    "\n",
    "  def run(self, policy=None, max_iter = 50000, verbose=False):\n",
    "    self.env.reset()\n",
    "    for i in range(50000):\n",
    "      action = self.choose_action(policy=policy)\n",
    "      obs, reward, done, info = self.env.step(action)\n",
    "\n",
    "      if verbose:\n",
    "        print(\"step i\",i,\"action=\",action)\n",
    "        print(\"obs=\",obs,\"reward=\",reward,\"done=\",done,\"info=\",info)\n",
    "      if done:\n",
    "        break\n",
    "\n",
    "  def train(self):\n",
    "    return None\n",
    "\n",
    "    \n",
    "a = agent()\n",
    "a.run(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQZof4jn9Bar"
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "env.reset()\n",
    "prev_screen = env.render(mode='rgb_array')\n",
    "plt.imshow(prev_screen)\n",
    "\n",
    "for i in range(50000):\n",
    "  action = env.action_space.sample()\n",
    "  print(\"step i\",i,\"action=\",action)\n",
    "  obs, reward, done, info = env.step(action)\n",
    "  print(\"obs=\",obs,\"reward=\",reward,\"done=\",done,\"info=\",info)\n",
    "  screen = env.render(mode='rgb_array')\n",
    "  \n",
    "  plt.imshow(screen)\n",
    "  ipythondisplay.clear_output(wait=True)\n",
    "  ipythondisplay.display(plt.gcf())\n",
    "\n",
    "  if done:\n",
    "    break\n",
    "    \n",
    "ipythondisplay.clear_output(wait=True)\n",
    "env.close()\n",
    "print(\"Iterations that were run:\",i)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "name": "APS1080 EX4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
